# 1강. 머신러닝 소개

## 1. 머신러닝의 개념

### 인공지능?

- 인공지능(AI: Artificial Intelligence)
  - 인간 지능을 모방해 문제 해결을 위해 사람처럼 학습 이해하는 기계를 만드는 분야
- 약인공지능(weak AI)
  - 실제 지능의 소유 여부 또는 처리 메커니즘과는 상관없이 지능적인 것처럼 행동하는 기계
  - 단지 정의된 특정 목적을 달성하고 문제를 해결해 나타나는 행동의 결과만 중시
- 강인공지능(strong AI)
  - 지능의 모방이 아닌 실제로 인간처럼 생각하는 기계
  - 스스로 문제 정의 및 해결, 지속적 학습, 자의식, 감정 등의 광범위한 지적 능력을 포함
  - Artificial General Intelligence (AGI), Human-level AI



### 머신러닝?

- 기계학습
  - 인간이 가지고 있는 고유의 지능적 기능인 학습 능력을 기계를 통해 구현하는 방법에 관한 분야
- 주어진 데이터 덩어리로부터 이를 분석하여 일반적인 규칙이나 새로운 지식을 **기계 스스로**가 자동으로 추출하기 위한 접근 방법



### 문제 풀이를 위한 접근 방법: 기존 방법 vs 머신러닝

- 기존에는 사람이 프로그램을 만들어서 문제 해결
- 머신러닝
  - 모델/구조를 만들고, 데이터를 제공, 학습 알고리즘을 적용해서 일반적인 규칙이나 새로운 규칙을 생성



### 머신 러닝

- 왜 필요한가?
  - 명시적인 지식 표현이나 프로그램을 만드는 것이 어렵거나 불가능한 경우
- 다양한 데이터의 변형을 다루기 위한 방법



### 딥러닝

- 심층학습(Deep learning)
- 심층 신경망 기반의 머신러닝 분야



### 인공지능, 머신러닝, 딥러닝의 관계

- 인공지능 > 머신러닝 > 딥러닝

| 구분 | 인공지능                           | 머신러닝                     | 딥러닝                       |
| ---- | ---------------------------------- | ---------------------------- | ---------------------------- |
| 정의 | 지능적인 기계 또는 프로그램의 개발 | 학습 능력을 활용한 문제 풀이 | 심층 신경망 기반의 학습 방법 |
| 예시 | IBM Deep Blue(chess)               | IBM Watson(의료진단 시스템)  | Alpha Go, ChatGPT            |



## 2. 머신러닝의 처리 과정

### 머신러닝의 처리 과정

- 학습 단계
  - 학습 데이터 집합
  - 데이터 전처리 과정
  - 특징 추출 
  - 학습(데이터 분석)
  - **함수 y=f(x)**
- 추론 단계
  - 테스트 데이터 
  - 전처리 데이터
  - 특징 추출
  - 분류, 회귀, 군집화
  - 판단 결과
- 입력 데이터
  - 학습 단계 → 학습 데이터
  - 추론 단계 → 테스트 데이터
- 전처리
  - 중복/불필요한 데이터 제거 및 분석에 용이한 형태로 데이터 가공/변환
  - 문제 및 입력 데이터 유형에 의존적, 머신러닝과 직접 관련 없음
- 특징 추출
  - 데이터 분석/처리를 위한 핵심적인 정보 추출
  - 데이터 특성에 의존, "어떤 핵심 정보를 줄 것인가"는 ML의 주요 문제



## 3. 머신러닝의 기본 요소

### 데이터 표현

- 머신러닝에서 데이터의 표현 → **랜덤 벡터**
  - n차원 열벡터



### 데이터 분포

- 데이터 집합 X → n x N 행렬 → X = [x1, x2, ... , xN]
- 데이터 집합의 분포 특성
  - 해당 공간상에서 점들이 분포된 모양
  - (예) 2차원 데이터 집합의 산점도 scatter plot
- 예
  - 모집단의 확률밀도함수
  - 등고선으로 표시된 밀도함수
  - 모집단의 데이터 분포
  - 4개의 표본집합



### 특징 추출

- 주어진 데이터를 처리하는데 핵심이 되는 정보를 추출
  - 목적 → 비용(계산량, 메모리) 절감, 데이터에 포함된 불필요한 정보 제거
    - 원영상
    - 격자 특징
    - 수직 히스토그램
    - 방향 성분
- 사영(projection)에 의한 특징 추출
  - 어떤 방향으로 사영하는 것이 좋은가?
    - 단순히 차원 축소가 아닌 데이터 처리를 위한 핵심 정보의 추출이 더 중요
    - 주어진 데이터의 분포 특성을 가장 잘 나타낼 수 있는 방향



### 성능 평가

- 학습 시스템
  - 데이터로부터 학습을 통해 추출하고자 하는 정보를 표현하는 시스템
  - 입, 출력 매핑 형태의 함수 y=f(x;θ)로 정의
- 학습?
  - 데이터를 이용해 함수 f를 찾는 것
  - 학습 시스템의 매개변수 θ를 찾는 것
- 학습의 궁극적 목표
  - 학습 데이터가 아닌 앞으로 주어진 데이터에 대한 성능을 최대로 하는 것
- 목적 함수 objective functon
  - 주어진 데이터 집합을 이용해 학습 시스템이 달성해야 하는 목표를 기계가 알 수 있는 수학적 함수로 정의한 것
- 오차함수 error function
  - 대표적인 목적함수
  - 원하는 출력값 yi와 학습 시스템의 f(xi;θ)의 차이(오차)로 정의
  - 학습의 목표 → 오차를 최소화하는 것
- 오차 함수를 사용한 성능 평가 기준
  - 학습 오차 training error
    - 학습 데이터 집합 X_train을 대상으로 계산된 오차
  - 테스트 오차 
    - test_error을 대상으로 계산된 오차
  - 일반화 오차 generalization error
    - 관찰될 수 있는 모든 데이터를 대상으로 정의되는 오차
    - 일반화 오차의 최소화가 실제 원하는 궁극적 목표 → p(x) 모른 → 실제 계산이 불가
    - 테스트 오차(=경험 오차empirical error)로 대신해 평가
- 교차검증법 cross validation method
  - 제한된 데이터 집합을 이용해 일반화 오차에 좀 더 근접한 오차값을 얻어내기 위한 방법
  - K-분절 교차검증법 K-fold cross validation



## 4. 머신러닝에서의 주제

### 머신러닝에서 다루는 주제

- 데이터 분석 data analysis
  - 분류
  - 회귀
  - 군집화
- 데이터 표현 data representation
  - 특징추출
    - 표현학습(딥러닝)(representation learning)



### (1) 분류(classification)

- 입력 데이터가 어떤 부류에 속하는지를 자동으로 판단하는 문제

  - "~인식" → 숫자인식, 얼굴인식, 생체, 음성, 객체 등
  - 베이즈 분류기, K최근접이웃방법, 결정 트리, 랜덤 포레스트, SVM, 신경망(MLP, CNN, LSTM)

- 분류 시스템의 입 출력의 관계

  - ```
    D = {xi, yi}i-1...N
    yi ∈ {0, 1, ... , M-1}
    ```

    - 분류의 출력은 이산적인 값

  - 학습 데이터 집합 > 학습 > 결정 경계 > 클래스 레이블

- 학습 결과

  - 결정경계(decision boundary), 결정함수(decision function)

- 학습 목표

  - 분류 오차를 최소화하는 최적의 결정경계를 찾는 것

- 성능 평가 척도

  - 분류율
    - 분류 성공 데이터 개수 / 전체 데이터 개수 * 100
  - 분류 오차
    - 분류 실패 데이터 개수 / 전체 데이터 개수 * 100



### (2) 회귀(regression)

- 입력 변수와 출력변수 사이의 매핑 관계 y=f(x;θ)를 찾는 것

- 예측

  - 시계열 예측(시장 예측, 환율 예측, 주가 예측, 판매 예측 등)
  - 선형회귀, 비선형회귀, 로지스틱 회귀, SVM, 신경망 등

- 회귀 시스템의 입출력 관계

  - ```D = {xi, yi}i-1...N
    D = {xi, yi}i=1...N
      yi ∈ R (실수)
    ```

    - 회귀의 출력은 실수

  - 학습 데이터 집합 > 학습 > 회귀함수 > 예측 결과

- 학습 결과

  - 회귀함수

- 학습 목표

  - 회귀 오차를 최소화하는 최적의 회귀함수 y=f(x;θ)를 찾는 것
  - 회귀 오차 → 제곱 오차



### (3) 군집화(clustering)

- 주어진 데이터 집합을 단순히 입력값의 유사성에 따라 서로 비슷한 임의의 복수 개의 그룹(군집 cluster)으로 묶는 문제

  - 데이터 그룹핑, 영상 분할 등
  - K-평균군집화, 계층적 군집화, 가우시안 혼합 모델 등

- 군집화 시스템의 입출력 관계

  - ```
    Prop{xnew ∈ Di}
    (i=1...K)
    ```

- 학습 결과

  - K개의 서로소(disjoint)인 부분집합(클러스터)
  - 각 클러스터의 대표벡터 또는 각 클러스터의 분포 함수도 가능

- 학습 목표

  - 최적의 클러스터의 집합을 찾는 것
    - "최적" → 클러스터 **내**의 분산은 **최소** 클러스터 **간**의 분산은 **최대**



### (4) 데이터 표현: 특징 추출(feature extraction)

- 원래 데이터로부터 분석에 적용하기 좋은 특징을 찾아내는 문제

  - 영상 데이터의 차원 축소, 데이터 시각화 등
  - 주성분분석(PCA), 성형판별분석(LDA), MDS, t-SNE
    - tSNE는 데이터 시각화에 많이 사용됨

- 특징 추출 시스템의 입출력 관계

  - ```
    z_new = f(xnew;θ)?
    ```

- 학습 목표

  - 분석 목적에 따라 달라짐
  - (예) 동일한 차원 축소를 한다고 해도 → 
    - PCA: 원래 데이터가 갖는 정보 손실량 최소화
    - LDA: 분류 정보 최대한 유지



## 5. 학습 시스템 관련 개념

### 머신 러닝의 유형

- Supervised 

  - Regression

    - SImple linear

  - Classification

    - Logistic regression
    - KNN
    - SVM
    - Kernel SVM
    - Naive Bayes

    Decision Tree

    Random Forest

    Artificial neural networks

    Convolutional neural networks

    Recurrent neural networks

    Transformers + Attention

- Unsupervised

  - Clustering
    - K-means
    - Hierarchical
  - Dimensionality Reduction
    - PCA



### 지도학습 Supervised learning 

- 학습할 때 시스템에 출력해야 할 목표 출력값을 함께 제공
- 분류, 회귀
- 클래스 레이블링 문제
  - 준/반semi지도학습, 약weak지도학습, 자가self지도학습

### 비지도학습 Unsupervised learning 

- 목표 출력값에 대한 아무런 정보 없이 학습을 진행
- 군집화

### 강화학습 Reinforcement

- 원하는 출력값을 모르거나 알 수 없는 경ㅇ
  - 출력값에 대한 교사 선호가 보상reward 형태
- 교사 신호는 정확한 값이 아니고, 출력값 각각에 대해 즉시 주어지지 않을 수 있음



### 과다 적합 overfitting

- 학습 시스템이 학습 데이터에 대해서만 지나치게 적합한 형태로 결정경계가 형성되는 현상
- 원인
  - 학습 데이터의 확률적 잡음과 학습 데이터 개수의 부족
- 영향
  - 일반화 성능 저하 초래
- 학습 시스템의 복잡도를 조정하는 방법
  - 다양한 변형을 가진 충분한 학습 데이터 사용
  - 조기 종료 early stopping 방법
  - 정규항을 가진 오차함수 사용
  - 여러 복잡도의 후보 모델을 학습한 후 최적 모델 선택 방법



### 머신러닝의 고급 주제

- 앙상블 학습(ensemble learning)
  - 복수 개의 간단한 학습 시스템을 결합해 일반화 성능을 향상시키는 방법
- 능동 학습(active learning)
  - 학습 과정에서 데이터를 선별적으로 선택해 수행하는 방법
- 메타 학습과 자동 머신러닝(meta-learning / auto ML)
  - 학습 시스템의 복잡도 등의 하이퍼파라미터까지 학습을 통해 최적화하는 방법
- 지속/증분 학습(continual/incremental learning)
  - 기존 학습 내용에 대한 손실 없이 새로운 내용을 추가로 학습