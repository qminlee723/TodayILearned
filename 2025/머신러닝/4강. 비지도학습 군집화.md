# 4강. 비지도학습: 군집화

## 1. 군집화의 개념

### 군집화(clustering)

<img src="./assets/Screenshot 2025-11-23 at 8.51.47 PM.png" alt="Screenshot 2025-11-23 at 8.51.47 PM" style="zoom:50%;" />

- 데이터 집합의 내재된 분포 특성을 분석해 서로 교차하지 않는 복수 개의 부분집합(cluster)으로 나누는 문제
  - 입력 데이터로부터 추출된 특징 공간에서 특징값의 유사성에 따라 스스로 비슷한 데이터끼리 묶어서 몇 개의 그룹으로 나누는 문제



### 분류와 군집화

<img src="./assets/Screenshot 2025-11-23 at 8.52.33 PM.png" alt="Screenshot 2025-11-23 at 8.52.33 PM" style="zoom:50%;" />

- **분류**에서는 바람직한 출력값을 제공하지만(클래스)
  - 지도학습
- **군집화**의 경우 입력값만 있음
  - 비지도학습



### 군집화

- 입출력의 관계

  - 학습 결과: 클러스터의 대표 벡터(평균)의 집합  → K-means

  <img src="./assets/Screenshot 2025-11-23 at 8.55.58 PM.png" alt="Screenshot 2025-11-23 at 8.55.58 PM" style="zoom:50%;" /> 

- 대표적 적용 방법

  - **K-평균 군집화(K-means clustering)**
  - **계층적 군집화(hierarchical clustering)**
  - 가우시안 혼합 모델(Gaussian mixture model)



### 군집화 적용의 예

- 군집화 적용이 가능한 데이터?
  - 데이터에 대한 클래스 레이블이 주어지지 않는 경우
  - 데이터에 대한 클래스 레이블링에 비용이 많이 드는 경우

- 예시
  - 장면 영상 데이터의 군집화
    - 비슷한거 모아봐!
  - 영상 화소의 군집화에 의한 영상 분할
    - 색상값 유사성에 따라서 분할



 ## 2. K-평균(대표 벡터) 군집화

### K-평균 군집화 알고리즘

- 주어진 데이터 집합을 평균 정보를 활용해 K 개의 그룹으로 묶는 알고리즘

  - 학습 결과 → 각 그룹에 속하는 데이터들의 평균 → "대표 벡터"

- 수행 단계

  <img src="./assets/Screenshot 2025-11-23 at 9.00.14 PM.png" alt="Screenshot 2025-11-23 at 9.00.14 PM" style="zoom:50%;" /> 

  - 시작(초기화)
    - 데이터 집합으로부터 **임의로 K개의 벡터를 선택**해, K개의 초기 대표 벡터 집합 생성
  - 데이터 그룹핑
    - 각 데이터 x에 대해 K개의 대표 벡터와의 거리 계산
    - 만약 데이터 xj가 대표 벡터 mk에 가장 가깝다면, 이 데이터를 클러스터 Ck에 속하도록 레이블링함
    - 이 두 과정을 통해 데이터 집합을 K 개의 클러스터로 나눔
  - 대표 벡터 수정
    - 2에서 구한 새로운 클러스트들에서 각각의 대표벡터 갱신
  - 반복 여부 결정
    - 수정 전의 대표 벡터와 수정 후의 대표 벡터의 차이를 계산해, 그 값에 변화가 없거나 설정된 반복 횟수에 도달할 때까지 단계 2~4 반복



### K-평균 군집화 알고리즘의 적용 예(K=2인 경우)

<img src="./assets/Screenshot 2025-11-23 at 9.04.48 PM.png" alt="Screenshot 2025-11-23 at 9.04.48 PM" style="zoom:50%;" />

<img src="./assets/Screenshot 2025-11-23 at 9.05.06 PM.png" alt="Screenshot 2025-11-23 at 9.05.06 PM" style="zoom:50%;" />



### 알고리즘의 특성

- 실제 문제에 적용해야 할 때 고려해야 할 3가지!
  - 대표 벡터 계산과 데이터 그룹핑 과정의 반복적인 수행을 통해 좋은 군집을 찾는 것이 확실히 보장되는가?
  - 초기 대표 벡터의 설정이 군집화 성능에 미치는 영향은?
  - 데이터에 의존하는 적절한 K 값을 어떻게 선택할 것인가?



#### (1) 반복수행 과정의 의미

- K-평균 군집화 알고리즘의 목적함수

  <img src="./assets/Screenshot 2025-11-23 at 9.10.27 PM.png" alt="Screenshot 2025-11-23 at 9.10.27 PM" style="zoom:50%;" /> 

- J 값: 각 클러스터 Ci의 분산을 모두 더한 값

  - J 값이 크다: 각 클러스터 내의 데이터들이 서로 뭉쳐 있지 않음
  - J 값이 작다: 각 클러스터 내의 데이터들이 잘 결집되어 있음

- **한 번 반복할 때마다 J의 값이 줄어드는 방향**으로 학습이 진행됨이 보장되어 있음

- J 값을 결정하는 파라미터

  - 대표벡터 m_i
  - 각 데이터에 대한 클러스터 레이블 r_ni

  <img src="./assets/Screenshot 2025-11-23 at 9.12.31 PM.png" alt="Screenshot 2025-11-23 at 9.12.31 PM" style="zoom:50%;" /> 

  - K-평균 군집화 알고리즘은 목적함수 J를 극소화하는 **지역 극소점**을 찾는 것을 보장

- 반복 횟수에 따른 J 값의 변화

  <img src="./assets/Screenshot 2025-11-23 at 9.17.21 PM.png" alt="Screenshot 2025-11-23 at 9.17.21 PM" style="zoom:67%;" />



#### (2) 초기값에 대한 의존성 문제

- 초기에 임의로 결정하는 대표 벡터에 따라 최종적인 결과가 달라짐 
  - 반복 횟수의 차이가 나거나(아래 이미지)
  - 결과 자체도 차이 일어날 수 있음

<img src="./assets/Screenshot 2025-11-23 at 9.18.11 PM.png" alt="Screenshot 2025-11-23 at 9.18.11 PM" style="zoom:50%;" />

- K-means 의 경우 학습에 큰 부담 없음
  - 어느 정도 거리가 있는 값들 선택
  - 전체 영역을 나눈 다음에 선택
  - 초기값을 변화시키면서 여러 번 반복 수행해서 최선의 결과 나오는거 확인



#### (3) K 값에 따른 변화

- 적절한 K값의 선정은 주어진 문제에 지극히 의존
- 적절한 K값 선정방법
  - 다양한 K값에 대해 군집화 결과들을 비교하여 모델을 선택하는 방법
  - 계층적 군집화 알고리즘의 사용





## 3. 계층적 군집화

### 계층적 군집화 알고리즘

- 전체 데이터를 몇 개의 배타적인 그룹으로 나누는 대신, 큰 군집이 작은 군집을 포함하는 형태로 계층을 이루도록 군집화를 수행해 그 구조를 살펴보는 방법

  - **병합적 방법 agglomerative, bottom-up**

    - 각 데이터가 하나의 군집을 이루는 **최소 군집**에서 시작해 **가까운 군집끼리 단계적으로 병합**해 더 큰 군집을 만들어 가는 방법
    - N개의 데이터 → **(N-1)번의 병합 과정** 수행

  - **분할적 방법 divisive, top-down**

    - N개의 모든 데이터가 하나의 군집에서 속하는 최대 군집에서 시작해 특정 기준에 따라 군집들을 분할해 가는 방법

    - N개로 이루어진 하나의 군집을 두 군집으로 분할하는 경우의 수 

      <img src="./assets/Screenshot 2025-11-23 at 9.25.26 PM.png" alt="Screenshot 2025-11-23 at 9.25.26 PM" style="zoom:50%;" /> → 비실용적(너무 많음)



### 병합적 방법의 수행 과정 예

<img src="./assets/Screenshot 2025-11-23 at 9.26.50 PM.png" alt="Screenshot 2025-11-23 at 9.26.50 PM" style="zoom:50%;" />



### 계층적 군집화 알고리즘: 병합적 방법의 수행 단계

<img src="./assets/Screenshot 2025-11-23 at 9.27.40 PM.png" alt="Screenshot 2025-11-23 at 9.27.40 PM" style="zoom:50%;" />



### 계층적 군집화 알고리즘의 특성

#### (1) 군집 간의 거리를 계산하는 방식?

- 최단 연결법 minimum/single linkage
  - 가장 가까운 데이터 쌍 간의 거리
  - 고립된 군집을 찾는데 유용

- 최장 연결법 maximum/complete linkage
  - 가장 멀리 떨어진 데이터 쌍 간의 거리
  - 응집된 군집을 찾는 데 중점
- 중심 연결법 centroid linkage
  - 두 군집의 평균 간의 거리
  - 특이값에 강건(outlier에 영향받지 않음)

- 평균 연결법 mean/average linkage
  - 각 군집에 속하는 모든 데이터 쌍 거리의 평균
  - 작은 분산을 가지는 군집을 형성
- Ward's 방법
  - 병합 후의 클러스터 내부의 분산값
  - 비슷한 크기의 군집을 병합

#### (2) 덴드로그램으로부터 적합한 군집의 수를 결정하는 방법?

- 덴드로그램에서 클러스터 간의 거리가 증가하는 동안, 클러스터 수의 변화 없이 일정 기간 유지되는 지점을 선택

  <img src="./assets/Screenshot 2025-11-23 at 9.31.01 PM.png" alt="Screenshot 2025-11-23 at 9.31.01 PM" style="zoom:67%;" /> 

