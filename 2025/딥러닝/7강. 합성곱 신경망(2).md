# 7강. 합성곱 신경망(2)

## 1. 합성곱 신경망의 구현

### 1. 합성곱 신경망

- 합성곱 신경망 개념도
  - 입력: 입력 데이터
  - 합성곱층: 데이터에서 특징 추출
  - 풀링층: 데이터의 차원 축소 - 연산량 감소 및 특징 강화
  - 완전연결층: 합성곱층과 풀링층을 거치면서 차원이 축소된 특징 맵을 1차원으로 변환. 소프트맥스를 통해 확률값으로 변환해 출력



### 2. 합성곱 신경망 구현

- TensorFlow 사용
  - FashionMNIST 데이터셋 제공
  - Numpy와 Matplotlib
- 데이터 준비
- 데이터 확인하기
- 범주 확인하기
  - `plt.figure()` 시각화할 전체 그림 크기 정의
  - `plt.imshow()` 반복문에서 선택된 이미지 시각화
  - `put.xlabel()` 해당 이미지의 레이블(범주)를 x 축 라벨로 표시

- 정규화하기
  - 경사소멸문제 해결
- 모델 생성하기
  - `keras.Sequential()` 사용해 모델 객체 생성
    - 모델 구성하는 레이어를 리스트 형태로 전달
    - 풀링층 `MaxPool2D`, `avepool2D`
    - `Flatten()`
    - `Dense()`
- 학습하기
  - `model.compile()`을 사용해 모델 컴파일
  - `model.fit()` 모델 학습을 위한 함수
  - `sparse_categorical_crossentropy` 데이터 레이블이 정수형일때 사용

- 손실함수의 선택

  - `sparse_categorical_crossentropy`
    - 데이터 범주의 값이 정수 형태
    - 원-핫-인코딩을 하지 않기 때문에 메모리 소요가 적음
  - `categorical_crossentropy`
    - 데이터 범주(클래스)의 값이 원-핫 인코딩인 형태
    - 예: 세 가지 색의 범주형 데이터

- 학습정보 함수 구현 및 확인하기

  - `history` 객체는 모델 학습 과정에서 발생한 손실과 정확도 정보 포함

  - `plot_loss()` 함수는 history라는 매개변수 받음

  - 5번의 에폭(epoch)

    <img src="./assets/Screenshot 2025-12-03 at 10.46.05 PM.png" alt="Screenshot 2025-12-03 at 10.46.05 PM" style="zoom:50%;" /> 

- 성능 평가 함수 구현 및 확인



## 2. LeNet-5 모델의 구성 및 특징

### 1. LeNet-5의 구조

- LeNet은 얀 르쿤(Yann LeCun) 연구팀이 1998년에 개발한 합성곱 신경망 모델로, 손글씨 이미지를 분류하기 위해 고안
  - LeNet은 LeNet-1, LeNet-4, 여러 개의 분류기를 사용하는 Boosted LeNet-4 등 다양한 버전이 존재
  - Boosted LeNet 앙상블 모델
  - Boosting(가중치 기반) Bagging(평균 기반)

- LeNet-5 모델의 세부 내용

  - 합성곱(Convolution)과 샘플링(Sampling)을 반복적으로 거친 후 완결연결층을 통해 분류를 수행하는 구조

    <img src="./assets/Screenshot 2025-12-03 at 10.49.04 PM.png" alt="Screenshot 2025-12-03 at 10.49.04 PM" style="zoom:50%;" /> 

    - Radial Basis Function(가우시안 연결 혹은 방사형 기저함수)
      - 가우시안 기반



### 2. LeNet-5의 계층

- 입력
  - MNIST는 60,000개의 학습데이터셋과 10,000개의 테스트데이터 셋으로 구성
  - 0-9까지의 값을 갖는 28x28 크기의 데이터
  - LeNet-5의 입력 크기는 32x32로 MNIST 데이터셋에 패딩을 넣어 32x32의 중앙에 위치시켜 처리
- C1: Feature maps
  - 5x5 필터 6개, 스트라이드 1, 활성함수 tanh 적용
  - 합성곱 연산 후 특징 맵의 크기는 28*28\*6
- S2: Feature maps
  - 6개의 28*28 크기의 특징 맵에 대해 2*2 평균 풀링, 스트라이드 2로 설정해 수행
  - 특징맵 6개는 28*28 -> 14\*14로 축소
- C3: Feature maps
  - LeNet-5 만의 독특한 방식으로 수행되는 연산
  - 합성곱 연산은 선택적으로 이용
  - 모든 특징 맵의 연결을 제한시킴으로써, 연산량 줄임
  - 서로 다른 입력 값을 취하므로, 각 특징 맵의 결과는 서로 다른 특징 맵을 상호보완적으로 추출
- S4: Feature maps
- C5 Layer(Convolution)
  - 활성함수 Tanh
- F6 Layer(fully-connected)
- 출력(Output)

- 방사형 기저함수
  - 입력값과 가중치 사이의 거리에 기반하여 값을 계산하는 함수
    - 비선형 방정식을 근사하기 위해 사용되며, 높은 차원의 입력 데이터를 저차원 공간으로 사상하는데 사용
    - 입력층과 Hidden Layer 사이에는 가중치 없음
    - Hidden Layer 1개 → MLP 보다 학습이 빠름
    - 선형 출력 층 → 가중치 계산 용이
    - 유클리드 거리



## 3. LeNet-5 모델의 구현

### 1. LeNet-5

-  LeNet-5 개념도
  - 합성곱과 샘플링을 반복적으로 거친 후, 완전연결층을 통해 분류를 수행하는 구조



### 2. LeNet-5의 구현

- 패키지 불러오기
  -  Keras, datasets, Sequential, Conv2D, MaxPooling2D, Dense, Flatten
  - 모델의 입력 데이터를 처리하기 위해 numpy import
- 데이터 준비하기
- 데이터 패딩 및 정규화하기
  - `reshape()` 이미지 데이터 형태 변경
  - `np.pad()` 이미지 데이터의 상, 하, 좌, 우 각각에 패딩 추가

- 레이블 데이터 벡터화하기
  - `to_categorical()` 정수 형태의 레이블 데이터를 원핫인코딩 형태로 변환
- 방사형 기저 함수 클래스 구현하기
- 모델 정의하기
  - `Sequential()` 생성, 여러개 층 차례로 추가해 모델 구성

- 학습하기
  - `model.compile()` 모델 컴파일
  - `model.fit()` 모델을 학습하기 위한 함수
  - <img src="./assets/Screenshot 2025-12-03 at 10.59.39 PM.png" alt="Screenshot 2025-12-03 at 10.59.39 PM" style="zoom:50%;" /> 
- 정확도 확인하기
  - `x_test`, `y_test`