# 6강. 합성곱 신경망(1)

## 1. 합성곱의 이해

### 1. 영상처리란?

- 영상처리
  - 디지털 이미지 조작, 분석, 인식, 생성 등의 목적을 달성하기 위한 기술
  - 합성곱 신경망(Convolutional Neural Network)은 이미지를 기반으로 한 영상처리 작업에서 우수한 성능을 보이는 신경망



### 2. 이미지의 구조

- 컬러 이미지 색상
  - 빨강, 초록, 파랑 세가지 색의 빛을 0~255의 다양한 강도로 섞어서 여러 색 표현
- 그레이 스케일 이미지 색상
  - 색상 정보 없이 오직 밝기 정보만으로 표현



### 3. 합성곱 연산

- 합성곱
  - 합성곱(Convolution)은 영상 처리 기술에서 가장 기본적인 연산
  - 합성곱 연산은 **필터링 연산**이라고 불리움
    - 필터와 이미지간 연산을 하는 것
  - 하나의 함수와 또 다른 함수를 반전 이동한 값을 곱한 다음, 구간에 대해 적분해 새로운 함수를 구하는 수학 연산자
- 합성곱 연산의 적용 사례
  - 포토샵, 사진 어플리케이션 필터
    - 이미지에 서로 다른 고정된 가중치 적용을 통해 윤곽선 검출/블로/샤픈/엠보싱 등 다양한 효과 
  - 다양한 객체 구분
    - 분류(classification)
    - 지역화(localization) - 어떤 위치에 있는지
    - 객체 탐지(Object detection) - 객체와 로컬라이제이션이 혼합된 형태
    - Instance Segmentation - 픽셀단위로 객체 탐지
  - 픽셀 복원
    - 이미지를 저해상도로 변환시킨 후, 각 이미지가 무엇과 유사한 형태를 보이는지 예측
  - 색복원
    - 흑백의 영상을 색있는 영상으로 변경



### 4. 합성곱 신경망의 필터

- 합성곱 신경망에서 어떻게 필터가 적용될까?
  - 이미지에 효과를 주는 기존의 필터링 기법은 고정된 필터를 통해 처리
  - 합성곱 신경망에서는 고정된 필터 사용하지 않음
  - 필터 가중치를 모르는 상태에서, 다양한 입력 데이터를 이용한 학습 과정을 통해 자동으로 가중치 결정



## 2. 합성곱 신경망의 구조

### 1. 합성곱 신경망 VS MLP

| 합성곱 신경망                                                | MLP                                                          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 입력 데이터의 공간적인 특징을 추출하는데 특화, 정보 손실 적음 | 입력 데이터를 1차원 배열로 만든 후, 신경망의 입력으로 사용해 가중치를 계산하므로 정보 손실 큼 |
| 필터 가중치 공유와 풀링층을 통한 데이터 크기 축소로 인해 연산이 효율적 |                                                              |



### 2. 합성곱 신경망의 주요 개념

<img src="./assets/Screenshot 2025-12-03 at 10.14.01 PM.png" alt="Screenshot 2025-12-03 at 10.14.01 PM" style="zoom:50%;" />

- **합성곱 신경망 개념도**
  - 입력: 입력 데이터
  - 합성곱층: 데이터에서 특징을 추출
  - 풀링층: **데이터의 차원을 축소하여, 연산량 감소 및 특징 강화**
  - 완전연결층: 합성곱층과 풀링층을 거치면서 차원이 축소된 특징 맵을 1차원으로 변환, 소프트맥스를 통해 확률값으로 변환해 출력
- 입력
  - 데이터가 합성곱 신경망에서 처리될 수 있도록 변환되는 단계
  - 데이터는 높이, 너비, 채널의 값인 3차원으로 구성
  - 컬러는 3개 채널, 그레이스케일은 1개 채널
  - (높이, 너비, 채널 수)로 표현
- 합성곱층
  - 합성곱 신경망에서 가장 많은 연산이 처리되는 계층
  - 이전 층에서 전달받은 입력 데이터와 필터(커널)를 통해 연산
  - 필터의 크기는 전통적으로 정방행렬의 3x3, 5x5, 7x7 등 홀수로 구성
  - 합성곱층의 산출물을 특징맵이라고 함

- 1개 채널의 합성곱 연산의 예

  - 1개 채널을 갖고 있는 4x4 크기의 데이터(4, 4, 1)에 3x3 크기의 필터를 적용한 합성곱 연산 과정

  - 그레이스케일 이미지에 필터를 2개 적용하면, 하나의 채널로 구성된 특징맵 2개

    <img src="./assets/Screenshot 2025-12-03 at 10.19.19 PM.png" alt="Screenshot 2025-12-03 at 10.19.19 PM" style="zoom:50%;" /> 

- 3개 채널의 합성곱 연산의 예

  - 3개 채널이 있는 4x4 크기의 데이터 (4, 4, 3)에 3x3 크기의 필터를 적용한 합성곱 연산

  - 채널의 수가 3개인 경우, 1개의 필터는 서로 다른 채널 별로 구성, 필터의 수는 1개

  - 컬러 이미지에 필터 2개를 적용하면, 2개의 특징 맵이 만들어짐

    <img src="./assets/Screenshot 2025-12-03 at 10.20.51 PM.png" alt="Screenshot 2025-12-03 at 10.20.51 PM" style="zoom:50%;" /> 

- 스트라이드

  - 입력 데이터에 필터가 적용돼 계산된 후 왼 > 오로 이동
  - 이 이동 간격을 stride로 부르며, 간격 조절 가능
  - 합성곱 연산 결과인 특징맵 크기는 필터 크기와 스트라이드에 의해 결정

- 패딩
  - 임의의 데이터 주변을 가상의 값으로 채우는 것
  - 패딩의 목적은 데이터의 특징을 **정밀하게 추출**하기 위한 것으로, 합성곱 연산을 마친 후 **출력 데이터의 크기를 입력 데이터의 크기와 같게 유지** 가능
  - 패딩은 선택사항
  - 모서리에 중요한 특징이 있다면, 특징을 정밀하게 추출하기 위해 사용

- 특징 맵의 크기

  - 5x5 입력 데이터에 3x3 크기의 필터를 적용

  - 스트라이드 1, 패딩의 크기 0

  - 입력 데이터는 5x5 에서 3x3으로 축소

    <img src="./assets/Screenshot 2025-12-03 at 10.23.22 PM.png" alt="Screenshot 2025-12-03 at 10.23.22 PM" style="zoom:50%;" />

- 합성곱층 코드

  - filters 필터의 수
  - kernel size 필터(커널)의 크기
  - strides - 필터가 움직이는 간격의 크기(기본값=(1,1))
  - padding - valid 아니면 same 사용. valid는 패딩 없음. same은 입력된 데이터 크기와 출력될 행렬 데이터 크기를 동일하게 맞춰줌(기본값 valid)
  - activation 사용할 활성함수(기본값 None)

  ```python
  tf.keras.layers.Conv2D(filters, 
                         kernel_size, 
                         strides=(1, 1), 
                         padding='valid', 
                         activation=None)
  ```

- 활성함수 종류

  - 텐서플로 API참조

  ```python
  elu
  gelu
  linear
  relu
  selu
  sigmoid
  softmax
  tanh
  ```

- 풀링층
  - 합성곱 층에서 연산된 출력 데이터를 입력으로 받아서, 크기를 줄이는 역할
  - 크기를 줄이므로 다운샘플링(down sampling) 혹은 서브 샘플링(sub sampling)이라고도 함
  - 합성곱 연산을 수행한 이후에 일반적으로 풀링층으로 구성
- 최대 풀링과 평균 풀링
  - <img src="./assets/Screenshot 2025-12-03 at 10.28.52 PM.png" alt="Screenshot 2025-12-03 at 10.28.52 PM" style="zoom:50%;" /> 
  - 합성곱으로 연산된 모든 데이터 특징을 활용하는 것이 아니고, **대표적인 특징만** 남기는 작업
  - 일반적으로 풀링 기법 중 최대 풀링을 많이 사용
  - 최대 풀링이 좀 더 효율적.
- 풀링의 특징
  - 데이터 크기가 작아지므로 연산량 작아짐
  - 풀링층은 합성곱층과 달리 학습을 위한 가중치가 없음
    - 풀링은 특정 영역에서 최댓값이나 평균을 취하는 처리 과정
  - 채널 수가 변하지 않음
    - 풀링 연산은 입력된 데이터의 채널 수대로 출력 데이터를 내보냄
  - 입력된 데이터가 일부 변경되더라도 풀링 결과는 크게 변하지 않음

- 풀링 후의 크기

  <img src="./assets/Screenshot 2025-12-03 at 10.30.53 PM.png" alt="Screenshot 2025-12-03 at 10.30.53 PM" style="zoom:50%;" /> 

- 풀링층 코드

  - pool_size: 풀링에 사용할 윈도우의 크기
  - Strides: 풀링에 사용할 윈도우가 움직이는 간격의 크기

- 완전연결층

  - 한 층과 그 다음 층이 완전히 연결된 상태
  - 완전연결층은 이전에 소개된 다층 퍼셉트론(MLP)를 지칭하는 또 다른 용어

- 소프트맥스

  - 출력층에서 사용되는 활성함수
  - 다중 클래스 분류 모델 만들 때 사용
  - 전체 클래스에 속할 확률을 0-1 사이의 값으로 정규화
  - 출력값들의 총합은 항상 1

- 완전연결층 코드

  ```python
  tf.keras.layers.Flatten(data_format=None)
  tf.keras.layers.Dense(units, activation=None)
  tf.keras.layers.Dense(units. activation=None)
  ```

  - Flatten(): 별도 매개변수 없이 구현
    - 2차원의 행렬 구조를 1차원의 벡터로 평탄화해주는 함수

  - units: 출력 노드(뉴런)의 수

  - activation: 사용할 활성함수