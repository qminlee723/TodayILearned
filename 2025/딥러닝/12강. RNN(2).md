# 12강. RNN(2)

## 1. [실습] RNN을 이용한 텍스트 생성 

### 1. 텍스트 생성 모델의 구조

<img src="./assets/Screenshot 2025-12-05 at 11.10.15 PM.png" alt="Screenshot 2025-12-05 at 11.10.15 PM" style="zoom:67%;" />





## 2. 인코더-디코더

### 1. 인코더-디코더

- encoder-decoder 개념

  - Seq2seq(sequence-to-sequence)라고도 불림
  - 인코더가 시퀀스를 입력으로 받아, 하나의 문맥 벡터(context vector)로 요약하면, 디코더가 문맥 벡터를 해석해서 출력 시퀀스를 만들어 내는 방식
  - 인코더-디코더 구조가 적용되는 주요한 예: 언어 번역

- 인코더-디코더의 구조

  <img src="./assets/Screenshot 2025-12-05 at 11.21.22 PM.png" alt="Screenshot 2025-12-05 at 11.21.22 PM" style="zoom: 67%;" />

  - 인코더와 디코더에 RNN 계열의 모델 사용
  - 기본 RNN 대신, LSTM 혹은 GRU 사용도 가능
  - 인코더에 번역할 문장의 단어들이 입력으로 들어감
  - 인코더 RNN의 마지막 은닉 상태가, 입력된 문장의 내용을 요약하는 문맥 벡터 C가됨
  - 디코더는 문맥 벡터 C를 입력으로 받아 번역된 문장을 이루는 단어들을 만들어 냄



### 2. 어텐션

- 어텐션(attention)의 아이디어

  - 인코더-디코더 구조에서 시퀀스의 길이가 길어지면, 시퀀스 앞쪽의 정보가 문맥 벡터(=RNN의 마지막 은닉 상태)에 거의 남아 있지 않게 되는 문제 발생
  - 어텐션 아이디어는 일괄적으로 문맥 벡터를 인코더의 마지막 은닉 상태로 하는 것이 아니라, **디코더에서 출력을 만들어 내는 시점**마다 상대적으로 더 중요한 부분에 관심을 가지도록 만드는 것

- 어텐션의 구조

  - 파란색이 인코더
  - 빨간색이 디코더

  <img src="./assets/Screenshot 2025-12-05 at 11.32.20 PM.png" alt="Screenshot 2025-12-05 at 11.32.20 PM" style="zoom:50%;" /> 

- 어텐션 맵

  <img src="./assets/Screenshot 2025-12-05 at 11.43.05 PM.png" alt="Screenshot 2025-12-05 at 11.43.05 PM" style="zoom:50%;" />

  - 셀이 밝을수록 해당 부분에 주목하는 가중치인 <img src="./assets/Screenshot 2025-12-05 at 11.42.26 PM.png" alt="Screenshot 2025-12-05 at 11.42.26 PM" style="zoom:50%;" /> 값이 큰 것을 나타냄
  - 영어를 프랑스어로 번역하는 과정에서, 비슷한 의미를 가진 단어에 대해 <img src="./assets/Screenshot 2025-12-05 at 11.42.26 PM.png" alt="Screenshot 2025-12-05 at 11.42.26 PM" style="zoom:50%;" /> 값이 큰 것을 볼 수 있음

- 어텐션 적용시의 성능 비교

  <img src="./assets/Screenshot 2025-12-05 at 11.44.01 PM.png" alt="Screenshot 2025-12-05 at 11.44.01 PM" style="zoom:50%;" />

  - 어텐션 적용된 모델(RNNsearch)이 긴 시퀀스를 더 잘 다룬다

  

