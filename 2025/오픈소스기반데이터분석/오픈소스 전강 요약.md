# 오픈소스 전강 요약

## 1강

- 데이터 분석은 데이터를 정리·처리·변환하여 유의미한 정보를 도출하는 과정이다.
- 데이터 분석은 인사이트와 가치 창출, 비효율적 프로세스 개선, 사회적 문제 해결데이터 기반 의사결정을 가능하게 한다.
- 데이터는 속성, 형태에 따라 다양하게 분류되며 그에 따른 분석 방법이 필요하다.



## 2강

- with문은 파일, 네트워크 연결 등 자원의 안전한 관리를 보장



## 3강

- 언패킹은 시퀀스 자료형 요소를 개별 변수에 효율적으로 할당한다.
- 함수형 프로그래밍은 반복문 없이 데이터 변환, 필터링, 축소 수행으로 코드를 간결화하고 병렬 처리에 적합한 구조를 제공하여 데이터 처리 성능을 향상시킨다.
- 람다 함수는 간결한 익명 함수로 즉시 정의 및 사용이 가능하다.
- map은 시퀀스의 모든 요소에 함수를 적용하여 **새로운 시퀀스**를 생성한다.
- filter는 조건을 만족하는 요소만 선택
- reduce()는 요소들을 순차적으로 처리하여 하나의 결과값으로 축약



## 4강

- 데이터 수집은 분석 목적에 적합한 데이터를 식별하고 데이터의 품질을 확보하는 전략적 과정이다.
- 좋은 데이터의 조건
  - 정확성
  - 완전성
  - 일관성
  - 유효성
  - 적시성
  - 상호운용성
- 파일 기반 수집은 로컬 환경이나 네트워크에서 파일을 직접 읽어 처리한다.



## 5강

- 데이터의 크기, 형태, 접근 빈도, 분석 목적에 따라 저장 방식이 달라진다.



## 6강

- 데이터 측정은 특성 파악과 전처리 필요성 판단을 위한 기초 단계이다.
- 데이터 통합은 여러 소스의 데이터를 결합하여 일관된 데이터셋을 구성한다.
- 데이터 변환은 정규화, 이산화 등을 통해 분석에 적합한 형태로 변형한다.



## 7강

- describe(), info() 함수를 통해 데이터의 기술 통계량과 구조를 파악한다.
- isnull(), isna() 함수를 사용하여 결측치를 탐지한다.
- interpolate(), fillna() 함수를 사용하여 결측치를 처리한다.
- IQR 방식이나 Z-점수를 활용하여 이상치를 탐지하고 처리한다.



## 8강

- 통계적 분석 기법에 해당하는 것은 무엇인가?
  - 회귀 분석
- 규칙 기반 분석은 투명성과 해석 가능성은 높지만 복잡한 패턴 포착에 한계가 있다.
- 통계적 모형은 확률론과 수리통계학에 기반하여 데이터의 분포, 변수 관계, 불확실성을 수학적으로 표현한다.
- EDA는 데이터의 특성과 구조를 이해하기 위한 분석 과정이다.



## 9강

- 회귀 분석은 독립변수가 종속변수에 미치는 영향을 정량화한다.
- 가설검정은 데이터를 바탕으로 통계적 추론을 통해 주장의 타당성을 평가한다.
- 분류 알고리즘은 데이터를 미리 정의된 범주로 구분한다.
- 회귀 알고리즘은 연속적인 값을 예측하며 다양한 분야에서 활용된다.
- 비지도학습(군집화, 차원 축소 등)은 레이블 없는 데이터에서 패턴이나 구조를 발견한다.
- CNN은 이미지 처리에, RNN, LSTM과 GRU는 시퀀스 데이터 처리에 특화되어 있다.
- 추론 통계 기법에 해당하는 것은?
  - 회귀 분석



## 10강



## 11강

- Bokeh와 Plotly는 어떤 시각화 방식에 해당하는가?
  - 인터랙티브
- 서브플롯을 활용하여 여러 그래프를 하나의 화면에 배치한다.



## 12강

- 원인이 파악되지 않는 데이터 분석 결과에 대해서는 급격한 변동 원인을 파악하기 위해 새로운 연관 데이터를 분석하여 해결할 수 있다.



## 13강

- 형태소 분석을 통해 문장을 품사 단위로 분리한다.
- 대규모 언어 모델(LLM)을 활용하여 게시글을 자동으로 분류할 수 있다.



## 14강

- CNN, VLM, LLM 등의 딥러닝 기술은 비정형 데이터를 해석하는 새로운 방법론을 제공한다.
- 필터링된 이미지를 대상으로 VLM을 활용하여 옷의 스타일, 색상, 트렌드 특징 등을 자연어로 설명하는 분석을 수행할 수 있다.
- 프롬프트 설계는 시스템 역할 정의, 사용자 지시사항, 데이터 반복 제공, **생성 매개변수 조정**을 포함하여 출력 품질을 높인다.



## 15강

- 시계열 데이터는 시간의 흐름에 따라 순차적으로 수집된 데이터로 
  - 추세
  - 계절성
  - 주기성
  - 불규칙성
- 이동평균(MA)의 주요 목적은 무엇인가?
  - 시계열 내 노이즈 제거 및 추세 파악
- 데이터 스누핑 편향(data snooping bias)의 주요 원인은?
  - 동일한 데이터셋 반복 사용
- 기술적 지표는 과거 가격과 거래량 데이터를 수학적으로 가공하여 얻은 값으로 시장의 추세, 모멘텀, 변동성 등을 파악하는 데 사용된다.
  - 이동평균, RSI 등의 기술적 지표
- Prophet 모델은 시계열 데이터를 
  - 추세, 계절성, 휴일 효과
- GBRT는
  - 앙상블 학습 기반의 머신러닝 기법
  - 잔차를 반복 학습
  - 비선형적 패턴을 효과적으로 모델링